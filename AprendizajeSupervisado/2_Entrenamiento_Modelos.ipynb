{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En todos los pasos, imprimir los resultados sobre el conjunto de entrenamiento y sobre el conjunto de test. Usar siempre GridSearchCV (con kfold) para encontrar los mejores parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/.anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (34,36,38,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/sneep-unificado-2002-2017-CURADO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selección de atributos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos usando el siguiente listado de atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['delito1_id','provincia_id','genero_id','nacionalidad_id',\n",
    "         'es_reincidente_id','anio_condenado','edad_al_ser_condenado',\n",
    "          'nivel_instruccion_id','estado_civil_id']].astype(int)\n",
    "y = data['duracion_condena_rango'].astype(int)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size = 0.10, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tareas a realizar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Crear una función que permita almacenar en un Dataframe de Pandas los siguientes datos:\n",
    "\"id_ejecucion\", \"tipo_modelo\", \"descripcion\", \"accuracy\", \"precision\", \"recall\". Para cada predicción sobre el modelo de test que realicemos cargar los resultados en este df, con el objetivo de tener un log de trabajo. Al finalizar guardar el df en un csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame \n",
    "log = pd.DataFrame(columns = [\"id_ejecución\", \"tipo_modelo\", \"descripcion\", \"accuracy\", \"precision\", \"recall\"]) \n",
    "# Save it to .csv\n",
    "log.to_csv(\"log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(num_ejec, y_pred, y_true=yTest, tipo_modelo=None, descripcion=None, df=log):\n",
    "    \"\"\"\n",
    "    Función que guarda los datos del modelo\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    df.loc[num_ejec] = ['ejec' + str(num_ejec)] + [tipo_modelo] + [descripcion] + [accuracy] + [precision] + [recall]\n",
    "    \n",
    "    df.to_csv(\"log.csv\")\n",
    "    \n",
    "    print(\"Reporte para el modelo número \" + str(num_ejec) + \" :\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Actualización de la tabla:\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También definimos una función para hacer la búsqueda de los mejores parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(model, params):\n",
    "\n",
    "    clf = GridSearchCV(model, params, cv=StratifiedKFold().split(xTrain, yTrain))\n",
    "    clf.fit(xTrain, yTrain)\n",
    "\n",
    "    print(\"Mejor conjunto de parámetros:\")\n",
    "    print(clf.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "    print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"Exactitud: %0.4f (+/-%0.04f) para los parámetros %r\" % (np.sqrt(mean), np.sqrt(std), params))\n",
    "        \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Entrenar un modelo con LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # En esta variable guardamos la cantidad de modelos ejecutados hasta el momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión Logística\n",
    "model = LogisticRegression(random_state=0) # semilla para reproducibilidad\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "desc = 'default parameters (penalty=l2, C=1.0, random_state=0)'\n",
    "\n",
    "save(num_ejec=i, y_pred=yPred, tipo_modelo='LogisticRegression', descripcion=desc) \n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos mejores parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_para = {'penalty':['l1','l2'], # l1 lasso l2 ridge\n",
    "             'C':np.logspace(-3,3,7),\n",
    "             'random_state':[0]\n",
    "             }\n",
    "\n",
    "model = grid(model = LogisticRegression(), params = logi_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego corremos el modelo con los mejores parámetros encontrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = model.best_params_\n",
    "\n",
    "model = LogisticRegression(penalty=best_params['penalty'],\n",
    "                           C=best_params['C'],\n",
    "                           random_state=best_params['random_state']\n",
    "                           )\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "desc = \"penalty={}, C={}, random_state={}\"\n",
    "desc = desc.format(str(best_params['penalty']),\n",
    "                str(best_params['C']), \n",
    "                str(best_params['random_state'])\n",
    "                )\n",
    "\n",
    "save(num_ejec=i, y_pred=yPred, tipo_modelo='LogisticRegression', descripcion=desc)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Entrenar un modelo de DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árbol de decision\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "desc = 'default parameters (criterion=gini, max_depth=None, max_features=None, random_state=0)'\n",
    "\n",
    "save(num_ejec=i, y_pred=yPred, tipo_modelo='DecisionTreeClassifier', descripcion=desc)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos mejores parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_para = {'criterion':['gini','entropy'],\n",
    "             'max_depth':[None, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 70, 90, 100, 110, 120, 130, 150],\n",
    "             'max_features':['auto', 'sqrt', 'log2', None],\n",
    "             'random_state':[0]\n",
    "            }\n",
    "\n",
    "model = grid(model = DecisionTreeClassifier(), params = tree_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos el modelo con los mejores parámetros encontrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = model.best_params_\n",
    "\n",
    "model = DecisionTreeClassifier(criterion=best_params['criterion'], \n",
    "                               max_depth=best_params['max_depth'],\n",
    "                               max_features=best_params['max_features'],\n",
    "                               random_state=best_params['random_state']\n",
    "                              )\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "desc = \"criterion={}, max_depth={}, max_features={}, random_state={}\"\n",
    "desc = desc.format(str(best_params['criterion']),\n",
    "                   str(best_params['max_depth']),\n",
    "                   str(best_params['max_features']), \n",
    "                   str(best_params['random_state'])\n",
    "                  )\n",
    "\n",
    "save(num_ejec=i, y_pred=yPred, tipo_modelo='DecisionTreeClassifier', descripcion=desc)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Entrenar un modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "model = RandomForestClassifier(random_state=0) \n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "desc = 'default parameters (n_estimators=10, criterion=gini, max_depth=None, max_features=auto, random_state=0)'\n",
    "\n",
    "save(num_ejec=i, y_pred=yPred, tipo_modelo='RandomForestClassifier', descripcion=desc) \n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos mejores parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_para = {'n_estimators':[5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 10, 80, 90, 100, 200, 300, 320, 350, 400, 450],\n",
    "             'criterion':['gini', 'entropy'],\n",
    "             'max_depth':[None, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 70, 90, 100, 110, 120, 130, 150, 200, 250],\n",
    "             'max_features':['auto', 'sqrt', 'log2', None],\n",
    "             'random_state': [0],\n",
    "            }\n",
    "\n",
    "model = grid(model = RandomForestClassifier(), params = rand_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(La celda anterior tardó aproximadamente un día en ejecutarse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos el modelo con los mejores parámetros encontrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = model.best_params_\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
    "                               criterion=best_params['criterion'],\n",
    "                               max_depth=best_params['max_depth'],\n",
    "                               max_features=best_params['max_features'],\n",
    "                               random_state=best_params['random_state']\n",
    "                              )\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "desc = \"n_estimators={}, criterion={}, max_depth={}, max_features={}, random_state={}\"\n",
    "desc = desc.format(str(best_params['n_estimators']),\n",
    "                   str(best_params['criterion']),\n",
    "                   str(best_params['max_depth']), \n",
    "                   str(best_params['max_features']),\n",
    "                   str(best_params['random_state'])\n",
    "                  )\n",
    "                \n",
    "save(num_ejec=i, y_pred=yPred, tipo_modelo='RandomForestClassifier', descripcion=desc)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Entrenar un modelo con XGBoost\n",
    "(Ejemplo: https://www.kaggle.com/rozester/xgboost-example-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost \n",
    "model = xgb.XGBClassifier(random_state=0)\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "desc = 'default parameters (max_depth=3, learning_rate=0.1, n_estimators=100, random_state=0)'\n",
    "\n",
    "save(num_ejec=i, y_pred=yPred, tipo_modelo='XGBClassifier', descripcion=desc) \n",
    "i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos mejores parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/.anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:629: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb_para = {'n_estimators':[5, 10, 15, 20, 25, 30, 35, 40, 50, 60, 10, 80, 90, 100, 200, 300, 320, 340, 350, 400],\n",
    "            'max_depth':[3, 6, 8, 9, 10, 11, 12, 15, 20, 30, 40, 50, 70, 90, 100, 110, 120, 130, 150, 200, 300],\n",
    "            'learning_rate':[0.01, 0.05, 0.1],\n",
    "            'random_state':[0]\n",
    "           }\n",
    "\n",
    "model = grid(model = xgb.XGBClassifier(), params = xgb_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(la anterior celda tarda días en ejecutarse, habría que enviarla al cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos el modelo con los mejores parámetros encontrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = model.best_params_\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=best_params['n_estimators'], \n",
    "                          max_depth=best_params['max_depth'],\n",
    "                          learning_rate=best_params['learning_rate'],\n",
    "                          random_state=best_params['random_state']\n",
    "                         )\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(xTest)\n",
    "\n",
    "desc = \"n_estimators={}, max_depth={}, learning_rate={}, random_state={}\"\n",
    "desc = desc.format(str(best_params['n_estimators']),\n",
    "                str(best_params['max_depth']), \n",
    "                str(best_params['learning_rate']),\n",
    "                str(best_params['random_state'])\n",
    "                )\n",
    "\n",
    "save(num_ejec=i, y_pred=yPred, tipo_modelo='XGBClassifier', descripcion=desc)\n",
    "i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
