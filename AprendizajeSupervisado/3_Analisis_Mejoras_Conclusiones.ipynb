{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizado el punto anterior, seleccionar uno de los modelos y realizar el siguiente análisis (se esperan respuestas cortas y concisas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELO ELEGIDO: **Random Forest** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/.anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (34,36,38,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../datasets/sneep-unificado-2002-2017-CURADO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['delito1_id','provincia_id','genero_id','nacionalidad_id',\n",
    "         'es_reincidente_id','anio_condenado','edad_al_ser_condenado',\n",
    "          'nivel_instruccion_id','estado_civil_id']].astype(int)\n",
    "y = data['duracion_condena_rango'].astype(int)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size = 0.10, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estos son los mejores parámetros encontrados con GridSearch en la notebook anterior\n",
    "best_params = {'n_estimators':450, \n",
    "               'criterion':'entropy', \n",
    "               'max_depth':20, \n",
    "               'max_features':'auto', \n",
    "               'random_state':0}\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=best_params['n_estimators'], \n",
    "                               max_depth=best_params['max_depth'],\n",
    "                               random_state=best_params['random_state'],\n",
    "                               max_features=best_params['max_features'],\n",
    "                               criterion=best_params['criterion']\n",
    "                              )\n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(xTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Comparar los resultados sobre el set de entrenamiento y sobre el set de test. ¿Qué podemos decir respecto a sesgo y varianza en estos resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta pregunta está relacionada con lo que se conoce como **the bias-variance tradeoff** (https://towardsdatascience.com/random-forests-and-the-bias-variance-tradeoff-3b77fee339b4). \n",
    "\n",
    "Se dice que un modelo está sesgado si sistemáticamente subestima o sobrestima la variable objetivo. Esto puede deberse a las suposiciones estadísticas hechas por el modelo elegido o a algún sesgo presente en los datos de entrenamiento.\n",
    "\n",
    "La varianza captura la capacidad de generalizar del modelo, ya que es una medida de cuánto cambiaría nuestra predicción si la entrenamos en diferentes datos. Una varianza alta indicaría que es posible que el modelo esté overfitteando. \n",
    "\n",
    "Por lo general, modelos con un sesgo más bajo en la estimación de los parámetros, tienen una varianza más alta y viceversa. Lo que nos gustaría, idealmente, es un sesgo bajo y una varianza baja.\n",
    "\n",
    "A continuación definimos una función que calcula el error cuadrático medio, la varianza y el sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variance(y_true, y_pred, e=0.05):\n",
    "    \"\"\"\n",
    "    Calcula el error cuadrático medio, la varianza y el sesgo\n",
    "    \"\"\" \n",
    "    mse = np.mean((y_pred - y_true)**2)\n",
    "    var = np.var(y_pred)\n",
    "    bias = mse - var - e\n",
    "    \n",
    "    print(\"Mean square error: %.2f\" % mse)\n",
    "    print(\"Bias: {bias}\".format(bias=bias))\n",
    "    print(\"Variance: {var}\".format(var=var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------\n",
      "SET DE TEST:\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Mean square error: 2.11\n",
      "Bias: -0.9525411629798166\n",
      "Variance: 3.0158337749635282\n",
      "-------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.13      0.20       288\n",
      "           2       0.56      0.77      0.65      2012\n",
      "           3       0.51      0.47      0.49      1658\n",
      "           4       0.57      0.51      0.54      1143\n",
      "           5       0.61      0.41      0.49       561\n",
      "           6       0.69      0.43      0.53       285\n",
      "           7       0.67      0.67      0.67       929\n",
      "\n",
      "    accuracy                           0.57      6876\n",
      "   macro avg       0.58      0.48      0.51      6876\n",
      "weighted avg       0.57      0.57      0.56      6876\n",
      "\n",
      "accuracy: 0.5706806282722513\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------------------------------------------------------------------------------\")\n",
    "print(\"SET DE TEST:\")\n",
    "print(\"-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "bias_variance(yTest, yPred)\n",
    "print(\"-------------------------------------------------------------------------------------------------\")\n",
    "print(classification_report(yTest, yPred))\n",
    "print('accuracy:', accuracy_score(yTest, yPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------\n",
      "SET DE ENTRENAMIENTO:\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------------------------------------------------------------------------------\")\n",
    "print(\"SET DE ENTRENAMIENTO:\")\n",
    "print(\"-------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "yPred2 = model.predict(xTrain)\n",
    "\n",
    "bias_variance(yTrain, yPred2)\n",
    "print(\"-------------------------------------------------------------------------------------------------\")\n",
    "print(classification_report(yTrain, yPred2))\n",
    "print('accuracy:', accuracy_score(yTrain, yPred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtuvimos una accuracy del 57% en el set de test, mientras que en el conjunto de entrenamiento la accuracy fué del 85%. También precision y recall dieron más alto en el conjunto de entrenamiento que en el de test (86% y 85% contra 57% y 57%). \n",
    "\n",
    "Por otro lado, el error cuadrático medio es mucho mayor en el set de prueba (2.11 contra 0.69), mientras que la varianza es casi la misma en ambos sets (3.02 y 3.06). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Imprimir la matriz de confusión de los resultados sobre el set de test. Desarrollar un análisis corto de lo que ven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función para graficar la **matriz de confusión**, esto nos ayudará a visualizar mejor los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['1', '2', '3', '4', '5', '6', '7']\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(yTest, yPred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(yTest, yPred, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.tight_layout()  # Optional ... often improves the layout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el modelo entrenado clasifica bastante bien a las clases '2', '4' y '7' y bastante mal a la clase '1' (casi siempre sobrestima hacia la clase '2'). El resto de las clases las clasifica mediocremente (ni tan bien, ni tan mal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Imprimir en una tabla (pueden crear un dataframe con los datos) la importancia relativa para el modelo de los distintos atributos (feature_importances_). Nuevamente, escribir un comentario respecto al resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/explaining-feature-importance-by-example-of-a-random-forest-d9166011959e\n",
    "\n",
    "https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejora del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Luego de realizado el análisis, es momento de intentar mejorar nuestro modelo. En ésta oportunidad, ustedes deben elegir al menos dos cambios a realizar para intentar mejorar los resultados. Los cambios pueden ser (pero no están limitados a): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agregar o quitar variables para entrenamiento (incluyendo otros delitos)\n",
    "- Cambiar el encoding de las variables\n",
    "- Recuperar registros que se filtraron al principio para tener más ejemplos\n",
    "- Filtrar mayor cantidad de registros\n",
    "- Generar una nueva variable (como se hizo con edad_al_ser_condenado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribir una conclusión breve respecto al trabajo. Particularmente sus ideas respecto a la pregunta inicial:\n",
    "¿Es posible predecir la duración de la condena que recibirá una persona en base a datos como los que se encuentran presentes en este dataset?\n",
    "\n",
    "Mencionar: \n",
    "- La calidad de los resultados obtenidos.\n",
    "- Causas posibles de problemas que hayan detectado.\n",
    "- Posibles soluciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
